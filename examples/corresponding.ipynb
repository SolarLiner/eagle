{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corresponding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.cm\n",
    "import pathlib\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image and convert to grayscale\n",
    "path: pathlib.Path = pathlib.Path('./images/tsukuba/scene1.row3.col1.ppm')\n",
    "img = numpy.array(PIL.Image.open(str(path)).convert('L'))\n",
    "\n",
    "figure = matplotlib.pyplot.figure(figsize=(10, 10))\n",
    "\n",
    "matplotlib.pyplot.axis('off')\n",
    "# matplotlib.pyplot.title('Image I')\n",
    "_ = matplotlib.pyplot.imshow(img, cmap=matplotlib.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write function to detect interst points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eagle.points.response\n",
    "\n",
    "# def find_interest_points(\n",
    "#     img: numpy.ndarray, \n",
    "#     size_neigh: int, \n",
    "#     epsilon: float\n",
    "# ) -> numpy.ndarray:\n",
    "#     r = eagle.points.response.kitchen_rosenfeld(img)\n",
    "#     rp = eagle.points.response.remove_non_maxima(r, size_neigh)\n",
    "#     points = eagle.points.response.select_with_threshold(rp, epsilon)\n",
    "#     return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find interset points and compute differentials invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eagle.points.response import \\\n",
    "    (\n",
    "        kitchen_rosenfeld,\n",
    "        remove_non_maxima,\n",
    "        select_with_threshold\n",
    "    )\n",
    "\n",
    "from eagle.points.descriptor.differential import DifferentialInvariant\n",
    "\n",
    "class ImageFeatures:\n",
    "\n",
    "    def __init__(self, img: numpy.ndarray):\n",
    "\n",
    "        self.img = img\n",
    "\n",
    "        # Find interest points\n",
    "        r = kitchen_rosenfeld(self.img)\n",
    "        rp = remove_non_maxima(r, size_neigh=3)\n",
    "        self.interest_points = select_with_threshold(rp, epsilon=0.3)\n",
    "\n",
    "        # self.nb_points = self.interest_points.shape[1]\n",
    "        \n",
    "        # Compute differential invaraint vector\n",
    "        self.differential_invariant = DifferentialInvariant(self.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs: list[numpy.ndarray] = []\n",
    "\n",
    "img_features: list[ImageFeatures] = []\n",
    "\n",
    "for img in imgs:\n",
    "    img_features.append(ImageFeatures(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find corresponding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute scores between differential invaraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_indices(indices: tuple[int, int]) -> tuple[int, int]:\n",
    "    i, j = indices\n",
    "    return i, j if j >= i else j, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eagle.points.descriptor.distance\n",
    "\n",
    "def compute_score(feature_1: ImageFeatures, feature_2: ImageFeatures) -> numpy.ndarray:\n",
    "\n",
    "    \"\"\" For each interest point from first feature, we compare interest point \\n\n",
    "    from second feature with the distance between differential invariant vector\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_pts_1 = feature_1.interest_points.shape[0]\n",
    "    nb_pts_2 = feature_2.interest_points.shape[0]\n",
    "\n",
    "    score = numpy.zeros(shape=(nb_pts_1, nb_pts_2))\n",
    "\n",
    "   \n",
    "\n",
    "    for i in range(0, nb_pts_1):\n",
    "\n",
    "        pt_i = tuple(feature_1.interest_points[i])\n",
    "        vec_i = feature_1.differential_invariant[pt_i]\n",
    "        \n",
    "        for j in range(0, nb_pts_2):\n",
    "\n",
    "            pt_j = tuple(feature_1.interest_points[j])\n",
    "            vec_j = feature_1.differential_invariant[pt_j]\n",
    "            distance = eagle.points.descriptor.distance.euclidean(vec_i, vec_j)\n",
    "\n",
    "            score[i, j] = distance\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_imgs = len(imgs)\n",
    "\n",
    "# Sym Matrix : idx_i, idx_j = i, j if j <= i else j, i\n",
    "scores = numpy.zeros(shape=(nb_imgs, nb_imgs), dtype=numpy.ndarray)\n",
    "\n",
    "for i in range(0, nb_imgs):\n",
    "    features_i = img_features[i]\n",
    "    for j in range(i+1, nb_imgs):\n",
    "        features_j = img_features[i]\n",
    "        scores[symmetric_indices((i, j))] = compute_score(features_i, features_j)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best corresponding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_imgs = len(imgs)\n",
    "\n",
    "EPSILON_DISTANCE = 0.001\n",
    "\n",
    "\n",
    "# Find j such as we have a maximum of corresponding\n",
    "# for i\n",
    "corresp = list[tuple[int, numpy.ndarray]] = []\n",
    "\n",
    "# corresp[i] index interest pts between i and j\n",
    "corresp_img = numpy.empty(shape=nb_imgs, dtype=int)\n",
    "\n",
    "corresp_pts = numpy.empty(shape=nb_imgs, dtype=numpy.ndarray)\n",
    "\n",
    "for i in range(0, nb_imgs):\n",
    "\n",
    "    best_pts: numpy.ndarray = corresp_pts\n",
    "    \n",
    "    for j in range(i+1, nb_imgs):\n",
    "        \n",
    "        score_ij: numpy.ndarray = scores[symmetric_indices(i, j)]\n",
    "        tmp = numpy.transpose(numpy.array(numpy.where(score_ij <= EPSILON_DISTANCE)))\n",
    "\n",
    "        if (best_pts is None) or (best_pts.shape[0] < tmp.shape[0]):\n",
    "            corresp_img[i] = j\n",
    "            corresp_pts[i] = best_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy.linalg\n",
    "\n",
    "\n",
    "def hartley_matrix(points: numpy.ndarray) -> numpy.ndarray:\n",
    "\n",
    "    n = points.shape[0]\n",
    "    mean = numpy.mean(points, axis=0)\n",
    "    \n",
    "    u_mean, v_mean = mean\n",
    "\n",
    "    center_points = points-mean\n",
    "    norms = numpy.sqrt(numpy.sum(center_points**2, axis=1))\n",
    "    a = numpy.sqrt(2) / numpy.mean(norms)\n",
    "\n",
    "    hartley_m = numpy.array(\n",
    "        [\n",
    "            [a, 0, -a*u_mean],\n",
    "            [0, a, -a*v_mean],\n",
    "            [0, 0, 1]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return hartley_m\n",
    "\n",
    "\n",
    "def hartley_normalization(points: numpy.ndarray, hartley_m: numpy.ndarray) -> numpy.ndarray:\n",
    "\n",
    "    a = hartley_m[0][0]\n",
    "    neg_au_mean = hartley_m[0][2]\n",
    "    neg_av_mean = hartley_m[1][2]\n",
    "    \n",
    "    u, v = points[:, 0], points[:, 1]\n",
    "\n",
    "    u_hartley = a*u + neg_au_mean\n",
    "    v_hartley = a*v + neg_av_mean\n",
    "\n",
    "    points = numpy.array([u_hartley, v_hartley]).T\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "# Ortogonal regression\n",
    "# Error varaible estimastion\n",
    "# Total Least Squares\n",
    "\n",
    "def homography_estimation(points_1: numpy.ndarray, points_2: numpy.ndarray, normalization: bool = False) -> numpy.ndarray:\n",
    "\n",
    "    pts1 = numpy.copy(points_1)\n",
    "    pts2 = numpy.copy(points_2)\n",
    "\n",
    "    # Hartey Normailzation\n",
    "\n",
    "    hartley_m1 = None\n",
    "    hartley_m2 = None\n",
    "\n",
    "    if normalization:\n",
    "        hartley_m1 = hartley_matrix(pts1)\n",
    "        # print(\"hartley_m1 =\", hartley_m1)\n",
    "        hartley_m2 = hartley_matrix(pts2)\n",
    "        pts1 = hartley_normalization(pts1, hartley_m1)\n",
    "        # print(\"pts1 (hartley) =\", pts1[0:2])\n",
    "        pts2 = hartley_normalization(pts2, hartley_m2)\n",
    "    \n",
    "    \n",
    "    # Total Least Square\n",
    "\n",
    "    nb_points = pts1.shape[0]\n",
    "\n",
    "    # u, v, up, vp = pts1[:, 0], pts1[:, 1], pts2[:, 0], pts2[:, 1]\n",
    "\n",
    "    D = numpy.zeros(shape=(2*nb_points, 9))\n",
    "\n",
    "    # print(u, v)\n",
    "    for i in range(0, nb_points):\n",
    "        \n",
    "        u, v = pts1[i]\n",
    "        up, vp = pts2[i]\n",
    "        # print(2*i,2*i+1)\n",
    "\n",
    "\n",
    "        D[2*i:2*(i+1)] = numpy.array(\n",
    "            [\n",
    "                [ u, v, 1, 0, 0, 0, -up*u, -up*v, -up ],\n",
    "                [ 0, 0, 0, u, v, 1, -vp*u, -vp*v, -vp ]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # print(\"D =\", D[0:3, 0:3])\n",
    "    DTD = D.T @ D\n",
    "    # print(\"D.T @ D =\", DTD[0:3, 0:3])\n",
    "    eigen_values, eigen_vectors = numpy.linalg.eig(DTD)\n",
    "    indmin = numpy.argmin(eigen_values)\n",
    "    v = eigen_vectors[:, indmin]\n",
    "\n",
    "    print(indmin)\n",
    "    \n",
    "    h = numpy.reshape(-v, newshape=(3, 3))\n",
    "\n",
    "    # Denormalization\n",
    "\n",
    "    if normalization:\n",
    "        h = numpy.linalg.inv(hartley_m2) @ h @ hartley_m1\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "ij = numpy.array(\n",
    "    [\n",
    "        [8.3439058171745160e+01, 3.9043662271609115e+01],\n",
    "        [8.3586419753086403e+01, 7.1055261312278859e+01],\n",
    "        [8.2210252727334861e+01, 2.5787845966349073e+02],\n",
    "        [8.1801443179097788e+01, 2.8886518678703118e+02],\n",
    "        [1.0984965715570684e+02, 6.3208884909560226e+01],\n",
    "        [1.0920333912015022e+02, 1.6481596306083208e+02],\n",
    "        [1.0826182446074708e+02, 2.6580010064461953e+02],\n",
    "        [1.9382238979515063e+02, 3.8608419735621922e+01],\n",
    "        [1.9277659792756745e+02, 1.6584636008778438e+02],\n",
    "        [1.9215537754306766e+02, 2.9327602811115213e+02],\n",
    "        [2.4589094080229816e+02, 2.3327981417837645e+01],\n",
    "        [2.4363060428849903e+02, 3.1131599564699832e+02]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "XY = numpy.array(\n",
    "    [\n",
    "        [0.0000000000000000e+00, 0.0000000000000000e+00],\n",
    "        [0.0000000000000000e+00, 4.5000000000000000e+00],\n",
    "        [0.0000000000000000e+00, 3.1500000000000000e+01],\n",
    "        [0.0000000000000000e+00, 3.6000000000000000e+01],\n",
    "        [1.8000000000000000e+01, 4.5000000000000000e+00],\n",
    "        [1.8000000000000000e+01, 1.8000000000000000e+01],\n",
    "        [1.8000000000000000e+01, 3.1500000000000000e+01],\n",
    "        [6.0000000000000000e+01, 4.5000000000000000e+00],\n",
    "        [6.0000000000000000e+01, 1.8000000000000000e+01],\n",
    "        [6.0000000000000000e+01, 3.1500000000000000e+01],\n",
    "        [7.8000000000000000e+01, 4.5000000000000000e+00],\n",
    "        [7.8000000000000000e+01, 3.1500000000000000e+01]\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hartley_m1 = [[ 0.01191906  0.         -1.71498205]\n",
      " [ 0.          0.01191906 -1.96966698]\n",
      " [ 0.          0.          1.        ]]\n",
      "pts1 (hartley) = [[-0.72046677 -1.50430315]\n",
      " [-0.71871035 -1.12275493]]\n",
      "D = [[-0.72046677 -1.50430315  1.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [-0.71871035 -1.12275493  1.        ]]\n",
      "D.T @ D = [[ 6.55576702e+00 -2.77408555e-02 -2.66453526e-15]\n",
      " [-2.77408555e-02  2.03280247e+01  1.77635684e-15]\n",
      " [-2.66453526e-15  1.77635684e-15  1.20000000e+01]]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.72301007e-01, -1.90250564e-03,  2.28520491e+01],\n",
       "       [-2.13325463e-02, -5.29729245e-02,  3.90491726e+00],\n",
       "       [-1.23876999e-03, -7.60194463e-06, -2.60520274e-01]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homography_estimation(ij, XY, normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8af255b71a47211f3bbb11e1d8c056494be1673d7ecf3fd6691ea74e9e18340"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
